{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4994f5a",
   "metadata": {},
   "source": [
    "## Spark Merge Two DataFrames with Different Columns or Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa504c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"proj\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e320ca",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://MOETD0216913.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>proj</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1dcd8bfb610>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64e3484",
   "metadata": {},
   "source": [
    "### Creating the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d13067ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = [{\"Category\": 'A', \"ID\": 1, \"Value\": 121.44, \"License\": True},\n",
    "        {\"Category\": 'B', \"ID\": 2, \"Value\": 300.01, \"License\": False},\n",
    "        {\"Category\": 'C', \"ID\": 3, \"Value\": 10.99, \"License\": None},\n",
    "        {\"Category\": 'E', \"ID\": 4, \"Value\": 33.87, \"License\": True}\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0afae2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = spark.createDataFrame(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4991d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = [{\"Category\": 'A', \"ID\": 5, \"Value\": 222.44, \"Age\": 37},\n",
    "        {\"Category\": 'B', \"ID\": 6, \"Value\": 500.01, \"Age\": 55},\n",
    "        {\"Category\": 'C', \"ID\": 7, \"Value\": 40.99, \"Age\": 22},\n",
    "        {\"Category\": 'E', \"ID\": 9, \"Value\": 30.87, \"Age\": 20}\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "df8edf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = spark.createDataFrame(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95a0a952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructField('Age', LongType(), True),\n",
       " StructField('Category', StringType(), True),\n",
       " StructField('ID', LongType(), True),\n",
       " StructField('Value', DoubleType(), True)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_2.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe16233",
   "metadata": {},
   "source": [
    "### Labelling Each DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "600c5882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a910b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.withColumn('Data', F.lit('Data_1'))\n",
    "df_2 = df_2.withColumn('Data', F.lit('Data_2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef1260b",
   "metadata": {},
   "source": [
    "### Merge using unionByName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "212a1ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df_1.unionByName(df_2, allowMissingColumns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "afa2a3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+-------+------+------+----+\n",
      "|Category| ID|License| Value|  Data| Age|\n",
      "+--------+---+-------+------+------+----+\n",
      "|       A|  1|   true|121.44|Data_1|null|\n",
      "|       B|  2|  false|300.01|Data_1|null|\n",
      "|       C|  3|   null| 10.99|Data_1|null|\n",
      "|       E|  4|   true| 33.87|Data_1|null|\n",
      "|       A|  5|   null|222.44|Data_2|  37|\n",
      "|       B|  6|   null|500.01|Data_2|  55|\n",
      "|       C|  7|   null| 40.99|Data_2|  22|\n",
      "|       E|  9|   null| 30.87|Data_2|  20|\n",
      "+--------+---+-------+------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08229bf5",
   "metadata": {},
   "source": [
    "### Doing it the old way since allowMissingColumns was only added in spark 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b4d231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [column for column in df_2.columns if column not in df_1.columns]:\n",
    "    df_1 = df_1.withColumn(column, F.lit(None))\n",
    "for column in [column for column in df_1.columns if column not in df_2.columns]:\n",
    "    df_2 = df_2.withColumn(column, F.lit(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5d4e8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df_1.unionByName(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "330cd3a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+-------+------+------+----+\n",
      "|Category| ID|License| Value|  Data| Age|\n",
      "+--------+---+-------+------+------+----+\n",
      "|       A|  1|   true|121.44|Data_1|null|\n",
      "|       B|  2|  false|300.01|Data_1|null|\n",
      "|       C|  3|   null| 10.99|Data_1|null|\n",
      "|       E|  4|   true| 33.87|Data_1|null|\n",
      "|       A|  5|   null|222.44|Data_2|  37|\n",
      "|       B|  6|   null|500.01|Data_2|  55|\n",
      "|       C|  7|   null| 40.99|Data_2|  22|\n",
      "|       E|  9|   null| 30.87|Data_2|  20|\n",
      "+--------+---+-------+------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "18f3c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3 = [{\"Category\": 'A', \"ID\": 1, \"Value\": 121.44, \"License\": [4, 5]},\n",
    "        {\"Category\": 'B', \"ID\": 2, \"Value\": 300.01, \"License\": [3, 2]}\n",
    "        ]\n",
    "df_3 = spark.createDataFrame(data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8e583ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| ID|col|\n",
      "+---+---+\n",
      "|  1|  4|\n",
      "|  1|  5|\n",
      "|  2|  3|\n",
      "|  2|  2|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_3.select('ID', F.explode('License')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7877bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
